# ðŸ“š **Complete LaTeX Research Paper Workflow for Data Science**
*From Empty Folder to Submission-Ready Paper*

---

## ðŸ—‚ï¸ **PROJECT STRUCTURE - ORGANIZATION IS KEY**

```
your-paper/
â”‚
â”œâ”€â”€ ðŸ“„ main.tex                    # Main document
â”œâ”€â”€ ðŸ“„ references.bib              # Bibliography
â”œâ”€â”€ ðŸ“„ custom.sty                  # Custom styles
â”œâ”€â”€ ðŸ“„ journal.cls                 # Journal template
â”‚
â”œâ”€â”€ ðŸ“ sections/                   # Paper sections
â”‚   â”œâ”€â”€ 00_abstract.tex
â”‚   â”œâ”€â”€ 01_introduction.tex
â”‚   â”œâ”€â”€ 02_related_work.tex
â”‚   â”œâ”€â”€ 03_methodology.tex
â”‚   â”œâ”€â”€ 04_experiments.tex
â”‚   â”œâ”€â”€ 05_results.tex
â”‚   â”œâ”€â”€ 06_conclusion.tex
â”‚   â””â”€â”€ 07_acknowledgments.tex
â”‚
â”œâ”€â”€ ðŸ“ figures/                    # All figures
â”‚   â”œâ”€â”€ plots/
â”‚   â”‚   â”œâ”€â”€ figure1.pdf
â”‚   â”‚   â”œâ”€â”€ figure2.pdf
â”‚   â”‚   â””â”€â”€ figure3.pdf
â”‚   â”œâ”€â”€ diagrams/
â”‚   â”‚   â”œâ”€â”€ architecture.pdf
â”‚   â”‚   â””â”€â”€ workflow.pdf
â”‚   â””â”€â”€ photos/
â”‚       â””â”€â”€ setup.pdf
â”‚
â”œâ”€â”€ ðŸ“ tables/                     # Table source files
â”‚   â”œâ”€â”€ dataset.tex
â”‚   â”œâ”€â”€ results.tex
â”‚   â””â”€â”€ comparison.tex
â”‚
â”œâ”€â”€ ðŸ“ code/                       # Code listings
â”‚   â”œâ”€â”€ algorithm.tex
â”‚   â”œâ”€â”€ implementation.tex
â”‚   â””â”€â”€ pseudocode.tex
â”‚
â”œâ”€â”€ ðŸ“ data/                       # Raw data for plots
â”‚   â”œâ”€â”€ results.csv
â”‚   â”œâ”€â”€ metrics.dat
â”‚   â””â”€â”€ training.csv
â”‚
â”œâ”€â”€ ðŸ“ appendix/                   # Appendices
â”‚   â”œâ”€â”€ appendix_a.tex
â”‚   â”œâ”€â”€ appendix_b.tex
â”‚   â””â”€â”€ proofs.tex
â”‚
â”œâ”€â”€ ðŸ“ templates/                  # Journal templates
â”‚   â”œâ”€â”€ neurips.sty
â”‚   â”œâ”€â”€ icml.sty
â”‚   â””â”€â”€ ieee.cls
â”‚
â”œâ”€â”€ ðŸ“ reviews/                    # Review comments
â”‚   â””â”€â”€ reviewer1_comments.tex
â”‚
â”œâ”€â”€ .gitignore                     # Version control
â”œâ”€â”€ Makefile                       # Build automation
â””â”€â”€ README.md                      # Project documentation
```

---

## ðŸ“ **STEP 1: SETUP & CONFIGURATION**

### **1.1 Main Document (main.tex)**
```latex
\documentclass[11pt,a4paper]{article}
% OR for conferences: \documentclass[conference]{IEEEtran}
% OR for journals: \documentclass[twocolumn]{article}

% ========== CUSTOM PACKAGE ==========
\usepackage{custom}

% ========== DOCUMENT METADATA ==========
\title{Your Paper Title: A Comprehensive Study}
\author{
    First Author\thanks{Corresponding author: email@domain.com} \\
    Affiliation 1 \\
    \and
    Second Author \\
    Affiliation 2
}
\date{\today}

% ========== HYPERREF SETUP ==========
\hypersetup{
    pdftitle={Your Paper Title},
    pdfauthor={Author Names},
    pdfkeywords={keyword1, keyword2, keyword3},
    pdfsubject={Data Science, Machine Learning},
    colorlinks=true,
    linkcolor=blue,
    citecolor=green,
    urlcolor=cyan,
    bookmarksnumbered=true
}

\begin{document}

% ========== FRONT MATTER ==========
\maketitle
\input{sections/00_abstract}
\input{sections/00_keywords}

% Optional: For double-blind review
%\begin{anonymous}
% Content here
%\end{anonymous}

% ========== MAIN BODY ==========
\begin{abstract}
\input{sections/00_abstract}
\end{abstract}

\keywords{Machine Learning, Data Science, Deep Learning}

\input{sections/01_introduction}
\input{sections/02_related_work}
\input{sections/03_methodology}
\input{sections/04_experiments}
\input{sections/05_results}
\input{sections/06_conclusion}

% ========== BACK MATTER ==========
\section*{Acknowledgments}
\input{sections/07_acknowledgments}

% ========== REFERENCES ==========
\bibliographystyle{plainnat}
\bibliography{references}

% ========== APPENDICES ==========
\appendix
\input{appendix/appendix_a}
\input{appendix/appendix_b}

\end{document}
```

### **1.2 Custom Style Package (custom.sty)**
```latex
\NeedsTeXFormat{LaTeX2e}
\ProvidesPackage{custom}[2024 Custom Package for Research Papers]

% ========== ESSENTIAL PACKAGES ==========
\RequirePackage{amsmath, amssymb, bm}      % Math
\RequirePackage{graphicx}                  % Figures
\RequirePackage[utf8]{inputenc}            % Encoding
\RequirePackage[T1]{fontenc}               % Better font encoding
\RequirePackage{booktabs}                  % Professional tables
\RequirePackage{array}                     % Better tables
\RequirePackage{multirow}                  % Multi-row tables
\RequirePackage{caption}                   % Better captions
\RequirePackage{subcaption}                % Subfigures
\RequirePackage{float}                     % Figure placement
\RequirePackage{placeins}                  % Float barriers

% ========== CITATIONS & REFERENCES ==========
\RequirePackage[numbers,sort&compress]{natbib}
\RequirePackage[colorlinks=true]{hyperref}
\RequirePackage{cleveref}                  % Smart references

% ========== CODE LISTINGS ==========
\RequirePackage{listings}
\RequirePackage{xcolor}

% ========== PAGE LAYOUT ==========
\RequirePackage{geometry}
\geometry{a4paper, margin=1in}
\RequirePackage{setspace}
\onehalfspacing  % 1.5 line spacing

% ========== MATH CUSTOMIZATIONS ==========
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Normal}{\mathcal{N}}
\newcommand{\Bernoulli}{\mathrm{Bern}}
\newcommand{\given}{\,|\,}

\newcommand{\bx}{\mathbf{x}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bw}{\mathbf{w}}
\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\balpha}{\boldsymbol{\alpha}}

\newcommand{\loss}{\mathcal{L}}
\newcommand{\risk}{\mathcal{R}}
\newcommand{\dataset}{\mathcal{D}}
\newcommand{\train}{\dataset_{\text{train}}}
\newcommand{\test}{\dataset_{\text{test}}}
\newcommand{\val}{\dataset_{\text{val}}}

% ========== ALGORITHM FORMATTING ==========
\RequirePackage{algorithm}
\RequirePackage{algpseudocode}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

% ========== THEOREM ENVIRONMENTS ==========
\RequirePackage{amsthm}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]
\newtheorem{remark}{Remark}[section]

% ========== CODE LISTING STYLES ==========
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}
\lstset{style=mystyle}

% ========== CUSTOM ENVIRONMENTS ==========
\RequirePackage{mdframed}
\newenvironment{important}
    {\begin{mdframed}[
        backgroundcolor=yellow!20,
        linecolor=yellow,
        linewidth=2pt,
        leftmargin=10pt,
        rightmargin=10pt
    ]}
    {\end{mdframed}}

\newenvironment{todo}
    {\begin{mdframed}[
        backgroundcolor=red!10,
        linecolor=red,
        linewidth=1pt,
        frametitle={TODO}
    ]}
    {\end{mdframed}}

% ========== HYPERREF CUSTOMIZATION ==========
\AtBeginDocument{
    \hypersetup{
        pdftitle={\@title},
        pdfauthor={\@author}
    }
}

\endinput
```

---

## ðŸ“„ **STEP 2: SECTION TEMPLATES**

### **2.1 Abstract (sections/00_abstract.tex)**
```latex
\begin{abstract}
This paper presents a novel approach for [problem]. 
We propose [method], which [key innovation]. 
Our method achieves [results] on [datasets], 
outperforming state-of-the-art methods by [margin]. 
The key contributions are: (1) [contribution 1], 
(2) [contribution 2], and (3) [contribution 3].
\end{abstract}

\keywords{keyword1, keyword2, keyword3, keyword4, keyword5}
```

### **2.2 Introduction (sections/01_introduction.tex)**
```latex
\section{Introduction}
\label{sec:introduction}

[Problem importance and context]. 
Recent advances in [field] have shown promise, 
but significant challenges remain in [specific problem].

\paragraph{Related Challenges:} 
(1) [Challenge 1], (2) [Challenge 2], 
(3) [Challenge 3].

\paragraph{Our Approach:}
We introduce [Method Name], which addresses 
these challenges through [key ideas].

\paragraph{Contributions:}
Our main contributions are:

\begin{itemize}
    \item \textbf{Novel Method:} We propose [method] 
          that [does something innovative].
    \item \textbf{Theoretical Analysis:} We provide 
          theoretical guarantees for [properties].
    \item \textbf{Empirical Validation:} Extensive 
          experiments on [number] datasets show 
          [performance improvement].
    \item \textbf{Open Source:} We release code at 
          \url{https://github.com/username/repo}.
\end{itemize}

\paragraph{Paper Organization:}
Section~\ref{sec:related} reviews related work. 
Section~\ref{sec:method} presents our methodology. 
Section~\ref{sec:experiments} details experiments. 
Section~\ref{sec:results} discusses results. 
Section~\ref{sec:conclusion} concludes.
```

### **2.3 Related Work (sections/02_related_work.tex)**
```latex
\section{Related Work}
\label{sec:related}

\subsection{Traditional Methods}
Early approaches to [problem] include 
\cite{author2015traditional} who proposed [method]. 
However, these methods suffer from [limitation].

\subsection{Deep Learning Approaches}
Recent deep learning methods \cite{author2018deep} 
have shown improved performance. 
\cite{author2020transformer} introduced [architecture], 
but requires [resource].

\subsection{Our Position}
Unlike previous work, our method [differentiation]. 
Specifically, we [unique aspect 1] and [unique aspect 2].
```

### **2.4 Methodology (sections/03_methodology.tex)**
```latex
\section{Methodology}
\label{sec:method}

\subsection{Problem Formulation}
Given dataset $\dataset = \{(\bx_i, y_i)\}_{i=1}^N$ 
where $\bx_i \in \R^d$ and $y_i \in \{0,1\}$, 
we aim to learn $f: \R^d \to [0,1]$ that minimizes:

\begin{equation}
\label{eq:loss}
\loss(f) = \frac{1}{N} \sum_{i=1}^N \ell(f(\bx_i), y_i) + \lambda R(f)
\end{equation}

\subsection{Proposed Architecture}
Our model architecture (Figure~\ref{fig:architecture}) 
consists of:

\begin{itemize}
    \item \textbf{Feature Extractor:} $h_\phi: \R^d \to \R^k$
    \item \textbf{Classifier:} $g_\theta: \R^k \to [0,1]$
\end{itemize}

The combined model is $f_{\theta,\phi} = g_\theta \circ h_\phi$.

\begin{figure}[ht]
\centering
\includegraphics[width=0.8\textwidth]{figures/diagrams/architecture.pdf}
\caption{Our proposed architecture.}
\label{fig:architecture}
\end{figure}

\subsection{Training Algorithm}
\begin{algorithm}[ht]
\caption{Our Training Procedure}
\label{alg:training}
\begin{algorithmic}[1]
\Require Dataset $\dataset$, learning rate $\eta$, epochs $T$
\Ensure Trained parameters $\theta, \phi$
\State Initialize $\theta, \phi$ randomly
\For{$t = 1$ to $T$}
    \State Sample batch $B \sim \dataset$
    \State Compute loss: $\mathcal{L} = \frac{1}{|B|} \sum_{(\bx,y)\in B} \ell(f(\bx), y)$
    \State Compute gradients: $\nabla_\theta \mathcal{L}, \nabla_\phi \mathcal{L}$
    \State Update: $\theta \leftarrow \theta - \eta \nabla_\theta \mathcal{L}$
    \State Update: $\phi \leftarrow \phi - \eta \nabla_\phi \mathcal{L}$
\EndFor
\State \Return $\theta, \phi$
\end{algorithmic}
\end{algorithm}
```

### **2.5 Experiments (sections/04_experiments.tex)**
```latex
\section{Experimental Setup}
\label{sec:experiments}

\subsection{Datasets}
We evaluate on three benchmark datasets:

\begin{table}[ht]
\centering
\caption{Dataset Statistics}
\label{tab:datasets}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Dataset} & \textbf{Samples} & \textbf{Features} & \textbf{Classes} & \textbf{Train/Test} \\
\midrule
MNIST & 70,000 & 784 & 10 & 60,000/10,000 \\
CIFAR-10 & 60,000 & 3,072 & 10 & 50,000/10,000 \\
IMDB & 50,000 & - & 2 & 25,000/25,000 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Baselines}
We compare against:
\begin{itemize}
    \item \textbf{Method A} \cite{author2018a}
    \item \textbf{Method B} \cite{author2019b}
    \item \textbf{Method C} \cite{author2020c}
\end{itemize}

\subsection{Implementation Details}
\begin{itemize}
    \item \textbf{Framework:} PyTorch 1.12
    \item \textbf{Hardware:} NVIDIA RTX 3090
    \item \textbf{Training:} Adam optimizer, $\eta=0.001$
    \item \textbf{Hyperparameters:} See Table~\ref{tab:hparams}
\end{itemize}

\begin{table}[ht]
\centering
\caption{Hyperparameter Settings}
\label{tab:hparams}
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
Learning rate & $10^{-3}$ \\
Batch size & 32 \\
Epochs & 100 \\
Weight decay & $10^{-4}$ \\
Hidden size & 256 \\
\bottomrule
\end{tabular}
\end{table}
```

### **2.6 Results (sections/05_results.tex)**
```latex
\section{Results and Analysis}
\label{sec:results}

\subsection{Main Results}
Table~\ref{tab:main_results} shows our method 
outperforms all baselines.

\begin{table}[ht]
\centering
\caption{Main Results (Accuracy \%)}
\label{tab:main_results}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Method} & \textbf{MNIST} & \textbf{CIFAR-10} & \textbf{IMDB} \\
\midrule
Method A \cite{author2018a} & 98.2 & 89.3 & 87.5 \\
Method B \cite{author2019b} & 98.5 & 91.2 & 88.3 \\
Method C \cite{author2020c} & 99.1 & 92.4 & 89.7 \\
\hline
\textbf{Ours} & \textbf{99.4} & \textbf{94.1} & \textbf{91.2} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Ablation Study}
\begin{table}[ht]
\centering
\caption{Ablation Study}
\label{tab:ablation}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Variant} & \textbf{Accuracy} & \textbf{$\Delta$} \\
\midrule
Full model & 94.1 & - \\
w/o Component A & 91.2 & -2.9 \\
w/o Component B & 92.4 & -1.7 \\
w/o Component C & 93.0 & -1.1 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Visual Analysis}
Figure~\ref{fig:tsne} shows t-SNE visualizations.

\begin{figure}[ht]
\centering
\begin{subfigure}{0.45\textwidth}
    \includegraphics[width=\textwidth]{figures/plots/before_tsne.pdf}
    \caption{Before training}
\end{subfigure}
\hfill
\begin{subfigure}{0.45\textwidth}
    \includegraphics[width=\textwidth]{figures/plots/after_tsne.pdf}
    \caption{After training}
\end{subfigure}
\caption{t-SNE visualizations}
\label{fig:tsne}
\end{figure}
```

### **2.7 Conclusion (sections/06_conclusion.tex)**
```latex
\section{Conclusion}
\label{sec:conclusion}

We presented [Method Name], a novel approach for [problem]. 
Our method achieves state-of-the-art performance on 
[number] benchmarks, demonstrating [key strengths].

\paragraph{Limitations:} 
Our method requires [computation/resources]. 
Future work includes [improvements].

\paragraph{Broader Impact:}
This work advances [field] and enables [applications].

\paragraph{Acknowledgments:}
We thank reviewers for feedback. Supported by [grants].
```

---

## ðŸ“š **STEP 3: BIBLIOGRAPHY MANAGEMENT**

### **3.1 references.bib**
```bibtex
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  volume={25},
  year={2012}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year={2016},
  publisher={MIT press}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}
```

### **3.2 Citation Commands**
```latex
% Basic citation
\cite{vaswani2017attention}

% Multiple citations
\cite{vaswani2017attention, krizhevsky2012imagenet}

% Author-year style
\citep{hochreiter1997long}
\citet{goodfellow2016deep}

% Page reference
\cite[Page 10]{kingma2014adam}
```

---

## âš™ï¸ **STEP 4: BUILD AUTOMATION**

### **4.1 Makefile**
```makefile
.PHONY: all clean view

# Main output
MAIN = main
BIB = references

# Build commands
all: $(MAIN).pdf

$(MAIN).pdf: $(MAIN).tex $(BIB).bib
    pdflatex $(MAIN)
    bibtex $(MAIN)
    pdflatex $(MAIN)
    pdflatex $(MAIN)

# Quick build (no bibliography)
quick:
    pdflatex $(MAIN)

# Clean auxiliary files
clean:
    rm -f *.aux *.log *.out *.toc *.lof *.lot
    rm -f *.bbl *.blg *.synctex.gz
    rm -f *.fdb_latexmk *.fls
    rm -f sections/*.aux

# View PDF
view: $(MAIN).pdf
    open $(MAIN).pdf  # macOS
    # xdg-open $(MAIN).pdf  # Linux
    # start $(MAIN).pdf  # Windows

# For arxiv submission
arxiv: clean
    mkdir -p arxiv
    cp $(MAIN).tex arxiv/
    cp $(BIB).bib arxiv/
    cp -r figures arxiv/
    cp -r sections arxiv/
    cp custom.sty arxiv/
    cd arxiv && zip -r ../submission.zip *
```

### **4.2 .gitignore**
```gitignore
# LaTeX auxiliary files
*.aux
*.log
*.out
*.toc
*.lof
*.lot
*.bbl
*.blg
*.synctex.gz
*.fdb_latexmk
*.fls
*.nav
*.snm
*.vrb

# PDF output
*.pdf

# Editor files
*.swp
*.swo
*~

# Temporary files
*.tmp
*.bak

# Python cache
__pycache__/
*.pyc
```

---

## ðŸ”§ **STEP 5: COLLABORATION WORKFLOW**

### **5.1 Review System**
```latex
% In custom.sty
\usepackage{xcolor}
\usepackage{todonotes}

% Color-coded comments
\newcommand{\reviewercomment}[2]{\todo[color=red!20,size=\small]{Reviewer #1: #2}}
\newcommand{\authorresponse}[1]{\todo[color=green!20,size=\small]{Response: #1}}
\newcommand{\actionitem}[1]{\todo[color=blue!20,size=\small]{TODO: #1}}

% Usage in paper
We propose a novel method\reviewercomment{1}{What makes it novel compared to X?}
\authorresponse{Our method differs in aspects A, B, and C.}
\actionitem{Add comparison table with method X.}
```

### **5.2 Version Control Branches**
```bash
# Branch structure
main
â”œâ”€â”€ develop
â”‚   â”œâ”€â”€ feature/new-method
â”‚   â”œâ”€â”€ feature/experiments
â”‚   â””â”€â”€ feature/writing
â”œâ”€â”€ submission/v1
â”œâ”€â”€ submission/v2
â””â”€â”€ camera-ready

# Commit messages
git commit -m "paper: Add methodology section"
git commit -m "experiments: Update results table"
git commit -m "figures: Add t-SNE visualization"
```

---

## ðŸ“Š **STEP 6: FIGURE GENERATION WORKFLOW**

### **6.1 Python Script for Plots (figures/generate_plots.py)**
```python
import matplotlib.pyplot as plt
import numpy as np
import matplotlib
matplotlib.use('pgf')  # For LaTeX integration

# LaTeX style plots
plt.rcParams.update({
    "text.usetex": True,
    "font.family": "serif",
    "font.serif": ["Computer Modern Roman"],
    "font.size": 10,
})

def save_plot(filename, dpi=300):
    """Save plot in multiple formats."""
    plt.tight_layout()
    plt.savefig(f"figures/plots/{filename}.pdf", bbox_inches='tight', dpi=dpi)
    plt.savefig(f"figures/plots/{filename}.png", bbox_inches='tight', dpi=dpi)
    plt.savefig(f"figures/plots/{filename}.pgf", bbox_inches='tight')
    plt.close()

# Example plot
x = np.linspace(0, 10, 100)
plt.plot(x, np.sin(x), label='Sine')
plt.plot(x, np.cos(x), label='Cosine')
plt.xlabel('$x$', fontsize=12)
plt.ylabel('$f(x)$', fontsize=12)
plt.legend()
save_plot('trig_functions')
```

### **6.2 TikZ for Diagrams (figures/architecture.tex)**
```latex
\documentclass[tikz]{standalone}
\usepackage{tikz}
\usetikzlibrary{arrows, shapes, positioning}

\begin{document}
\begin{tikzpicture}[
    node distance=1.5cm,
    block/.style={rectangle, draw=black, thick, fill=blue!20, 
                  text width=3cm, text centered, rounded corners},
    arrow/.style={->, >=stealth, thick}
]

\node[block] (input) {Input Data};
\node[block, below=of input] (feature) {Feature Extractor};
\node[block, below=of feature] (classifier) {Classifier};
\node[block, below=of classifier] (output) {Predictions};

\draw[arrow] (input) -- (feature);
\draw[arrow] (feature) -- (classifier);
\draw[arrow] (classifier) -- (output);

\end{tikzpicture}
\end{document}
```

---

## ðŸ“‹ **STEP 7: QUALITY CHECKLIST**

### **Before Submission:**
```latex
% Check these in your main.tex
% \documentclass{...} - Correct journal/conference style
% \usepackage{...} - All required packages
% \title{...} - Complete title
% \author{...} - All authors with affiliations
% \abstract{...} - Within 150-250 words
% \keywords{...} - 3-5 keywords
% All \label{...} exist and are unique
% All \ref{...} and \cite{...} resolve
% Figures: All .pdf files exist in figures/
% Tables: All data correct and formatted
% Bibliography: All entries cited in text
% Compile: pdflatex -> bibtex -> pdflatex (x2)
% Page limit: Within journal/conference limits
% File size: PDF < 10MB (usually)
```

### **Common Issues to Fix:**
```latex
1. Overfull \hbox -> Adjust line breaks
2. Float too large -> Reduce figure width
3. Undefined references -> Run pdflatex twice
4. Missing citations -> Check .bib file
5. Font warnings -> Install missing fonts
```

---

## ðŸš€ **STEP 8: SUBMISSION READY**

### **8.1 Final Compilation Script (build.sh)**
```bash
#!/bin/bash

echo "Cleaning previous builds..."
make clean

echo "Building PDF..."
pdflatex -interaction=nonstopmode main.tex
bibtex main
pdflatex -interaction=nonstopmode main.tex
pdflatex -interaction=nonstopmode main.tex

echo "Checking for errors..."
# Check for undefined references
if grep -q "undefined references" main.log; then
    echo "WARNING: Undefined references found!"
fi

# Check for overfull boxes
if grep -q "Overfull" main.log; then
    echo "WARNING: Overfull boxes found!"
    grep "Overfull" main.log | head -5
fi

echo "Build complete: main.pdf"
```

### **8.2 Conference/Journal Specific**
```latex
% IEEE Conference
\documentclass[conference]{IEEEtran}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{amsmath}

% NeurIPS
\documentclass{article}
\usepackage{nips_2023}  % Download from conference site

% ICML
\documentclass{article}
\usepackage{icml2023}  % Download from conference site

% ACM
\documentclass[sigconf]{acmart}
\usepackage{balance}
```

### **8.3 Camera-Ready Version**
```latex
% Add this after \begin{document}
\begin{anonymous}  % For double-blind review
% OR remove for camera-ready
\end{anonymous}

% Add copyright notice
\copyrightyear{2024}
\acmYear{2024}
\setcopyright{acmcopyright}
\acmConference[]{Conference Name}{2024}{City, Country}
\acmPrice{15.00}
\acmDOI{10.1145/xxxxxx.yyyyyy}
\acmISBN{978-1-4503-XXXX-X/18/06}
```

---

## ðŸ“ˆ **WORKFLOW SUMMARY**

### **Daily Workflow:**
```
1. git pull origin develop
2. Edit sections/section.tex
3. Generate/update figures
4. Compile: make quick
5. Check output
6. git add -A
7. git commit -m "description"
8. git push origin branch
```

### **Weekly Workflow:**
```
Monday:    Write methodology/results
Tuesday:   Generate figures/tables
Wednesday: Write introduction/related work
Thursday:  Edit and polish
Friday:    Get feedback, fix issues
Weekend:   Major revisions
```

### **Submission Timeline:**
```
- 8 weeks before: First complete draft
- 6 weeks before: Internal review
- 4 weeks before: Revise based on feedback
- 2 weeks before: Final editing
- 1 week before: Format checking
- 3 days before: Final compilation
- 1 day before: Submit!
```

---

## ðŸ’¡ **PRO TIPS FOR EFFICIENT WORKFLOW**

1. **Use Overleaf for collaboration** - Real-time editing
2. **Git for version control** - Track all changes
3. **Zotero/Mendeley** - Reference management
4. **Python scripts** - Auto-generate tables/figures
5. **Makefile** - One-command compilation
6. **Separate content from style** - custom.sty
7. **Modular sections** - Easy to reorganize
8. **Continuous integration** - Auto-build on changes

---

## ðŸŽ¯ **ONE COMMAND TO RULE THEM ALL**

Create `compile.sh`:
```bash
#!/bin/bash
# Full compilation pipeline
pdflatex main.tex
bibtex main
pdflatex main.tex
pdflatex main.tex
open main.pdf  # Or your PDF viewer
```

Run: `./compile.sh` or `make all`

---

**Final Advice:** Start with the structure, fill in content gradually, compile often, get feedback early, and leave time for final polishing. The key to a successful research paper in LaTeX is organization and incremental progress.

